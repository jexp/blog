= Schneller sperren - Stamped Lock in Java 8

Eine der interessanten, aber auch komplexeren Neuzugänge in Java 8 ist eine neue Form von Sperre (Lock) namens StampedLock, die besonders für den Fall des konkurrierenden Zugriffs von häufigen und vielen lesenden und wenigen, seltenen schreibenden Beteiligten, deutliche Leistungszuwächse verspricht. Dafür sorgt ein optimistischer Ansatz, der kostengünstig für den Fall is, dass es während eines Lese _versuchs_ keinen konkurrierenden Schreibzugriff gab. Dann muss keine teure Sperre gesetzt werden, man kann stattdessen mit günstigeren, optimistischen Mechanismen auskommen.

== Konkurrenz - was tun?

Sobald man konkurrierend aus mehreren Threads auf gemeinsame, geteilten Ressourcen oder Speicherstellen zugreifen will oder muss, ist dringend der Bedarf an einer Koordinationslösung gegeben. Was uns im sequentiellen Modus nicht gestört hat, nimmt beim gemeinsamen Zugriff bedrohliche Ausmasse an.

Am besten wäre es, immer mit unveränderlichen (immutablen) Datenstrukturen auszukommen, oder die genutzten Informationen gleich gar nicht zu teilen. Man kann auch grundsätzlich nur einen Thread Zugriff gewähren, den man über Aufrufe oder Botschaften mit neuen Informationen versorgt. 

Das alles ist aber leider nicht immer machbar, so dass es notwendig wird, sich die Koordinationsmöglichkeiten in Java genauer anzuschauen.

Die Benutzung der Code-Bereiche "kritische Sektionen", die auf dieselben Resourcen(gruppen) zugreifen, muss also koordiniert werden. Zum Teil für einen exklusiven Zugriff, zum Teil für gemeinsamen Zugriff (z.b. wenn mehrere Konsumenten nur lesen).

Neben den in der Sprache integrierten Methoden zur Synchronisation, gibt es noch diverse Hilfsklassen im JDK, besonders im Paket `java.util.concurrent`. Welche dieser Methoden nun genutzt wird ist u.a. von der Länge und Art der kritischen Bereiche, sowie von der Anzahl und Häufigkeit von konkurrierenden, parallelen Lese- und/oder Schreibzugriffen abhängig. Das ist besonders spannend, wenn diese Verhältnisse sich während der Laufzeit der Anwendung ändern, was in realen Anwendungsfällen durchaus geschieht.

Wie immer sollte die Wahl des "besten" Ansatzes sowohl nach gründlicher Überlegung als auch praktischer Messung (Mikrobenchmark und realer Anwedungsfall) erfolgen.

== Synchronized 

Die älteste und bekannteste Methode der der Synchronisation in Java heisst auch so `synchronized`. Dabei wird entweder auf der Klasse, der Instanz oder auf einem Lock-Objekt eine exklusive Sperre für eine Methoder einen Block gesetzt, so dass nur ein Thread zur gleichen Zeit, diesen Block durchlaufen kann. Dabei wird nicht zwischen Lese- und Schreiboperationen unterschieden. 

Falls sich schon ein Thread im Codeblock befindet, werden alle anderen Threads in einen Wartezustand (suspend) gesetzt. Wenn der Thread den `synchronized` Block verlässt, werden sie aufgeweckt, Prozessorcache-Notifikationen und Speicherbarrieren ausgelöst und dann einer der Threads ausgewählt, um den Block als nächstes zu betreten. Es findet praktisch eine Serialisierung des Zugriffs statt. Selbst wenn es praktisch keine konkurrierenden Zugriffe gibt, addieren sich die zusätzlichen Prüfungen und Operationen zu einem deutlichen Geschwindigkeitsverlust auf. Gute Beispiel dafür, dass pauschale Synchronisation keine gute Idee ist, sind `StringBuffer` vs. `StringBuilder` und `Vector` vs. `ArrayList`.

Synchronized ist reentrant, dh. derselbe Thread kann wieder in die Methode eintreten, ohne blockiert zu werden.

== Optimierungen durch Hotspot

Dieser Mechanismus ist exklusiv und ziemlich teuer, kann aber bei Kenntnis der Abläufe (kleine Blöcke, wenige Threads, seltene konkurrierende Zugriffe) trotzdem geeignet sein. Besonders weil neuere JVMs einige Tricks im Ärmel haben, um diese Sperren zu optimieren. Besonders, wenn es seltene konkurrierende Zugriffe auf die geschützten Bereiche gibt, können diese angewandt werden.

Zum einen können mittels _biased-locking_ die teuren Operationen zum Erlangen des "Leases", dass die Vorraussetzung zur Erteilung einer Sperre darstellt, minimiert werden. Besonders in Fällen, die nur wenig konkurrierende Zugriffe, aber dafür eine Schleife über einen synchronisierten Bereich enthalten, ist die immerwährende Erzeugung des Leases sehr teuer. Daher können seit Java 6, Threads in einer solchen Schleife solange die Freigabe des Leases vermeiden, solange nicht ein anderer Thread den Zugriff benötigt. Damit begünstigt (biased) die Sperre den wiederkehrenden Aufrufer. Es wird aber nicht die Sperre um die ganze Schleife gelegt, um andere Threads nicht auszusperren.

Desweiteren gibt es zwei Wege, ungenutzte oder unnütze Sperren ganz zu beseitigen. Zum einen _lock-coarsening_ - damit wird aneinandergereihtes Erlangen derselben Sperre zusammengefasst, z.b. aufeinanderfolgende Aufrufe synchronisierter Methoden desselben Objekts. Durch Inlining der Methoden kann der synchronisierte Bereich vergrössert werden, so dass er den gesamten Code umfasst, und die Sperre nur einmal angefordert werden muss. Der größere gesperrte Bereich hat aber natürlich Auswirkungen auf das Laufzeitverhalten, besonders die Fairness gegenüber anderen Threads.

Und mit _lock elision_ wird der reale Gültigkeitsbereich (Scope) von Lock-Objekten überprüft (mittels Escape-Analyse). Werden Referenzen auf das Lock (z.b. Objekt-Instanz bei synchronized Methoden) nie ausserhalb des aktuellen Scopes (so auch für andere Threads) zugreifbar, können die Sperrmechianismen ganz entfernt werden.

Das Parken der Threads, die den kritischen Bereich nicht betreten konnten ist eine ziemlich teure Operation für JVM, OS und Hardware. Daher kann es, gerade bei sehr kurz gehaltenen Sperren sinnvoll sein, die wartenden Threads in einer Schleife des Nichtstuns verharren (_Spin Lock_) zu lassen, bevor wiederholt getestet werden kann, ob die Sperre verfügbar ist. In Java 4 waren das einfach kurze Schleifen von 10 Iterationen. Java 6 führte einen dynamischen Ansatz (_adaptive Spinning_) ein, wobei bisherige Erfahrungen mit dieser Sperre und dem aktuellen Thread mit einfliessen. Bis zu 100 Iterationen können dann CPU-Zyklen "verbrannt" werden, oder halt gar nicht, wenn es in der Vergangenheit auch nicht gereicht hat.

Diese Optimierungen sind von vielen Rahmenbedingungen abhängig und können nicht pauschal für jede Situation vorausgesetzt werden.
Mittels anderer Sperren, kann man selbst kontrollieren, ob man lesenden oder schreibenden Zugriff unterscheiden will, ob die Sperren an andere Threads oder Methoden weitergegeben werden können oder ob man die Sperren von weiteren Bedingungen abhängig machen will.

Das JDK hat noch diverse andere Hilfsklassen, um Sperren von Bereichen zu ermöglichen. Ich möchte mich hier nur auf das `ReentrantReadWriteLock` beschränken, da es als zu ersetzender "Vorgänger" des `StampedLock` gilt.

== ReentrantReadWriteLock

Alle Concurrency-Hilfsklassen im JDK haben nicht den Vorteil von `synchronized`, direkt Teil der Sprache und des JVM-Modells zu sein. Daher sind sie zum einen auf Operationen beschränkt, die jedem anderen Code auch offenstehen, zum anderen machen sie massiven gebrauch von `sun.misc.Unsafe`, um ihre Arbeit zu leisten. Um an bestimmte Speicherbarrieren auszulösen oder CPU-Instruktionen wie Compare-And-Swap auszuführen, müssen sie diesen Weg nehmen.

Das `ReentrantReadWriteLock` war vor Java 8 eine häufig genutzte Sperre, die an sich ganz praktisch war, da sie zum einen mittels eines Sperr-Objektes, sowohl Lese- als auch Schreibzugriffe synchronisieren konnte.

Desweiteren ist es reentrant, dh. wenn derselbe Thread erneut dieselbe Sperre anfordert, wird er einfach durchgelassen (mit Erhöhung von Zählern), auch wenn das über mehrere Methodenaufrufe weit entfernt geschieht. Das ist auch praktisch, wenn ausgehend von einer Schreibsperre, andere Methoden aufgerufen werden, die erneute Lese-Sperren im aktuellen Thread anfordern.

Normalerweise ist das `ReentrantReadWriteLock` nicht fair, dh. Lese- oder Schreiboperationen können potentiell beliebig lange verzögert werden. Da dieser Ansatz der performantere ist und es in der Praxis im Allgemeinen nicht vorkommt dass Threads ausgeschlossen werden, ist der "nicht-faire" Modus standardmässig aktiv.

Der "faire" Modus ist deutlich langsamer, da Zugriffswünsche aufgezeichnet, und ausgeglichen behandelt werden müssen. Entweder der am längsten wartende Schreib-Thread oder die gemeinsam am längsten wartende Gruppe von Lese-Threads werden bevorzugt behandelt.

Schreibsperren können zu einer Lese-Sperre umgewandelt werden (indem innerhalb sie vor der Freigabe der Schreibsperre angefordert werden), aber nicht umgekehrt. Eine zugeteiltes Read-Lock kann nicht zu einem Write-Lock aufgewertet werden. Diese Möglichkeit gibt es erst mit dem StampedLock.

[source,java]
----
private final ReentrantReadWriteLock lock = new ReentrantReadWriteLock();
...
public float updateAndComputeAverage(int value) {

  // kurzer geschützter Bereich
  lock.writeLock().lock();
  try {
	sum += value;
	count ++;
	// Umwandlung zu Read-Lock
	lock.readLock().lock();
  } finally { 
    lock.writeLock().unlock();
  }
  try {
	return (float)(sum / count);
  } finally {
    lock.readLock().unlock();
  }
}
----

Der Nachteil am ReentrantReadWriteLock liegt an der Performance, besonders wenn häufig viele lesende und selten schreibende Threads aktiv sind. Dann ist die zwangsweise Zuteilung eines Read-Locks eine relativ teure Angelegenheit, sie kostet ca. 2000 Prozessorzyklen, was eine ganze Menge ist.

== StampedLock

Genau um diese Probleme zu adressieren, wurde das `StampedLock` in Java 8 eingeführt. Doug Lea hatte es schon vor einiger Zeit entwickelt, daher gibt es auch einen Backport zu Java 7. Wie im `ReentrantReadWriteLock` wird zwischen exklusiven (Write) und geteilten (Read) Sperren unterschieden. Die größte Neuerung sind schnelle, optimistische Optionen für lesende Operationen.

Die Hauptziele des StampedLock sind ein höherer Durchsatz wenn viele lesende Threads gleichzeitig auf den kritischen Bereich zugreifen. Desweiteren die Möglichkeit ein Read-Lock zu einem Write-Lock aufzuwerten.

=== Vorteile

* sehr schnelle, optimistische Lese-Sperren
** in den meisten Fällen gibt es keine Konflikte zwischen Lese- und Schreiboperationen, in diesen sollte die Leseoperation sehr performant sein
** wenn die Ausnahme auftritt, dass während der Leseoperation eine Schreibsperre angefordert wird, wird das optimistische Token automatisch ungültig
** dann kann ein erneuter Versuch gestartet oder ein richtiges Read-Lock angefordert werden

* höherer Durchsatz, besonders wenn deutlich mehr Lese- als Schreib-Threads um die Sperre konkurrieren
* Möglichkeit zum Aufwerten einer Lesesperre zur Schreibsperre
* Stamp-Token kann weitergegeben werden, andere Methoden können ihn benutzen oder umwandeln

=== Nachteile

* nicht so einfach zu benutzen (siehe auch "Bedingungen"), man muss aufpassen, stets die korrekten Methoden zu benutzen
* nicht *reentrant*, 
** d.h. wenn derselbe Thread wieder in einen Bereich kommt, der auf demselben Lock eine Sperre anfordert, wird er auch geblockt, 
** muss über Weitergabe des Tokens gehandhabt werden
** daher muss aufgepasst werden, welche anderen Methoden (möglichst keine) im kritischen Bereich aufgerufen werden, so dass der Thread nicht versehentlich sich selbst blockiert
* Leseoperationen müssen Seiteneffektfrei sein (reine Berechnungen), sonst können sie nicht nach einer fehlgeschlagenen Validierung (beliebig oft) wiederholte werden
* Token benutzen endlichen Wertebereich
** laufen nach einem Jahr über
** sind nicht "sicher", können erraten werden
** ungültige Token für Operationen (ausser `validate`) zu benutzen kann zu unvorhergesehenen Auswirkungen führen
* StampedLock ist `Serializable` aber wird in nicht-gesperrten Zustand deserialisiert, also nicht für verteilte Sperren nutzbar


=== Modi
==== Schreib-Lock 

* Exclusiv
* Akquisition mit `writeLock()`, wenn nicht gerade Read-Lock aktiv ist, dann Blockierung (ggf. Timeout bei `writeLock(time,timeUnit)`)
* Freigabe mit `unlockWrite(stamp)`
* Read-Locks werden blockiert
* optimistische Leseanforderungen schlagen fehl
* fair, kontinuierlich ankommende Lese-Threads können wartende Schreib-Threads nicht aushungern
* Downgrade zu Read-Lock mittels `tryConvertToReadLock(stamp)`
* Downgrade/Release mittels `tryConvertToOptimisticRead(stamp)`

==== Read-Lock

* geteilt mit anderen Lese-Threads
* Akquisition mittels `readLock()` wenn nicht gerade Write-Lock aktiv ist, dann Blockierung (ggf. Timeout bei `readLock(time,timeUnit)`)
* Wenn Read-Lock aktiv ist und kein Write-Thread warted, dann Partizipation in aktuellem Lock
* Upgrade zu Write-Lock mittels `tryConvertToWriteLock()`
** wenn schon in Write-Mode, oder kein weiterer Lese-Thread oder im optimistischen Modus und kein Lock gesetzt
* Downgrade/Release mittels `tryConvertToOptimisticRead(stamp)`

==== Optimistisch Lesen

Der optimistische Ansatz für die Leseoperation funktioniert wie folgt:

1. Vor dem Lesezugriff, versucht man mit `tryOptimisticRead()`, sich einen Lese-Token geben zu lassen
.. dieser ist 0 wenn schon ein Write-Lock gehalten wird
2. Man liest von den Feldern, aber nur einmalig und atomar, daher wird oft (z.B. wenn man ihn später noch benötigt), der Wert einer lokalen Variablen zugewiesen
.. dieses Code-Segment sollte so kurz wie möglich sein, nur dann kommt auch die Leistungssteigerung zum Tragen
3. Mittels `validate(token)` überprüft man die Gültigkeit des Tokens von Erhalt bis zum aktuellen Zeitpunkt, d.h. kein anderer Thread hat mittlerweile einen Schreibzugiff über das Lock angefordert
.. `validate` kann auch mehrmals aufgerufen werden, um sicherzustellen, dass gelesene Werte nicht völlig inkonsistent sind
.. man sollte die zu lesenden Datenstrukturen sehr gut kennen, besonders ihre Konsistenzzusammenhänge, um zwischenzeitliche Fehlersituationen zu vermeiden
.. das gilt auch für Methoden die mit den gelesenen Werten aufgerufen werden, diese sollten auch mit inkonsistenten Werten umgehen können (oder man muss vorher ein `validate` die Konsistenz bestätigen lassen)
.. Wenn das `validate` erfolgreich ist, kann man den berechneten Wert nutzen oder zurückgeben
.. Wenn nicht kann man entweder eine explizite Lesesperre mittels `readLock()` anfordern, 
.. oder den optimistischen Zugriff in einer Schleife wiederholen, bis er erfolgreich ist (oder eine Kombination aus beiden mit einer beschränkten Anzahl von Versuchen)
.. bei höheren Anzahlen von Lese-Threads, sollte die Anzahl der Versuche des optimistischen Lesens erhöht werden, da die Wahrscheinlichkeit des Erfolgs ziemlich hoch ist

.Optimistische Leseoperation
[source,java]
----
class Counter {
    private final StampedLock sl = new StampedLock();
    int sum;
    int count;

    public float getAverage() {
        long stamp = sl.tryOptimisticRead();
        int s = sum, c = count; // in lokale Variablen kopieren
        if (sl.validate(stamp)) return c == 0 ? 0 : (float)(s / c);

        stamp = sl.readLock();
        try {
            return count == 0 ? 0 : (float) (sum / count);
        } finally {
            sl.unlockRead(stamp);
        }
    }
}
----

=== Bedingungen

Für die korrekte Funktionsweise des optimistischen Ansatzes, besonders für die *Nutzung der gelesenen Werte in Berechnungen* innerhalb t des kritischen Codebereiches, müssen folgende Bedingungen beachtet werden:

1. Atomare Leseoperationen 

Da keine Speicherbarrieren (ala volatile oder synchronized) für den Zugriff hinzugefügt werden, müssen alle Zugriffe atomar sein (was bei 32 bit Feldern sowieso, und bei 64-bit Feldern meist der Fall ist). Sonst kann ein anderer Schreib-Thread den Wert teilweise ändern, während man ihn gerade liest.

2. Invarianten

Ähnliches gilt für Invarianten d.h. semantische Abhängigkeiten zwischen gelesenen Werten, auch diese können durch ebendiesen Fakt verletzt werden, so dass eine Berechnung, die auf dieser Abhängigkeit aufbaut, im besten Fall unerwartete Ergebnisse liefert im schlechtesten Fall aber zu einer Exception führt (was bei einer Leseoperation unerwartet ist).

3. Garbage Collection

Wenn Referenzen, die gelesen werden sollen zwischenzeitlich entsorgt wurden, dann ist das auch kontraproduktiv. Normalerweise beim Java-Garbage Collector passiert das nicht, aber wenn man Dinge in die eigene Hand nimmt, z.b. mit eigenen Speicherstrukturen, oder off-heap Speicher sollte man dies bedenken.

Wenn man Martin Thompson (Mechanical Sympathy, Disruptor, Lock-Free Algorithms, Simple Binary Encoding, Aeron) zuhört, dann stellt sich natürlich die Frage, warum man denn schon wieder eine neue Sperre benötigt, und ob nicht mit etwas mehr Nachdenken ein Ansatz/Algorithmus gewählt werden könnte, der ohne Sperren auskommt. Dazu mehr in einer der nächsten Kolumnen.


=== Arbeitsweise - Wie funktioniert das StampedLock intern?

==== Zustand und Token 
Das StampedLock benutzt intern Algorithmen und Speicherbarrieren, die erst in Java8 hinzugefügt wurden. Damit ist es schneller und auch robuster als bisherige Ansätze.

Der Zustand des Locks wird intern durch eine Version und einen Modus abgebildet. Sowohl dieser Zustand als auch die Zeiger auf die Warteschlange sind auf eine Cache-Line optimiert, so dass sie für Lesezugriffe immer gemeinsam konsistent zur Verfügung stehen.

Der zurückgegebene Stamp-Token repräsentiert diesen Zuststand. Die `try`-Versionen der Methoden können ggf. 0 zurückgeben, falls sie fehlschlagen. Ansonsten schlagen `release` und `convert` Operationen fehl, wenn der Token nicht dem aktuellen Zustand entspricht.

StampedLock benutzt Sequence Locks (wie im Linux Kernel) und geordnete Read-Write-Locks. Intern gibt es eine Sequenz-Nummer, die ungerade für Write-Locks und sonst gerade is, mehrere parallele Reader werden in einem Offset gehalten bis zu 7 Bit (komfortable 128 Threads) in Bitfeld, sonst in einem Überlaufsfeld für (unerwartet) größere Mengen von lesenden Threads.

Die Validierung von Sequenznummern benötigt stärkere Zusicherungen als nur einzelne volatile Lesezugriffe. Es muss erzwungen werden, dass die Aktualisierung der Sichtbarkeit der Felder vor der Ausführung der Validierung passiert ist. Wenn das noch nicht durch andere Trigger geschehen ist, muss es mit Unsafe.loadFence() (seit Java 8) ausgelöst werden.

==== Warteschlange 

Referenzen auf die Threads, die auf die Zuteilung der Sperre warten, werden in einer doppelt verkettete Liste (CLH-Lock-Queue) von "Waiter"-Knoten gehalten. 
Jeder Knoten ist als Lese- oder Schreibthread markiert. Lese-Threads hängen an einem Gruppenknoten, so dass sie gemeinsam aufgeweckt werden können. 
Normalerweise würden Reader gleich mit zum Zuge kommen, wenn gerade eine Lese-Sperre vorliegt, der Fairness (Phase-Fair) halber wird aber sobald auch ein Schreib-Thread in der Warteschlange steht, auch der aktuell angekommene Leser eingereiht. Diese Fairness-Mechanismen führen zu einer höheren Komplexität in der `aquireRead` Methode. Aber auch die `aquireWrite`-Methode ist ziemlich umfangreich, da sie auf konsistenten Sets von gelesenen Variablen beruhen gibt es keine extrahierten Methoden, sondern viel ähnlichen "kopierten" Code für die alternativen Zweige.

Über die Knoten der Liste wird sowohl das Management der Blockierung, als auch das Aufwecken des nächsten in der Reihe (FIFO) gesteuert. 
Notifizierte Threads bekommen nicht automatisch die Sperre, sie sind nur die nächsten mit der Gelegenheit, sie anzufordern.

Neue wartende Threads werden am Ende mit einer atomaren Operation eingefügt. Genauso wird das Umsetzen des Kopf-Zeigers (head) atomar ausgeführt. Aufwändiger ist es, (bedingt durch Timeouts und Interrupts) herauszufinden, wer denn der nächste potentielle Nachfolger ist. Herauslöschen abgebrochener Knoten erfolgt durch Ermittlung der Vorgänger und Nachfolger, sowie Neuverlinkung der beiden Zeiger auf Vorgänger und Nachfolger. Um den Nachfolgern zu erlauben, sicher selbst festzustellen, ob sie auch abgebrochen wurden und ihren neuen Vorgänger zu akzeptieren werden sie kurz "entparkt". Ggf. enstehende Race-Conditions zwischen Herauslöschen entfernter Threads und dem Hinzufügen neuer am Ende, wird durch zusätzliche Checks Rechnung getragen.

////
----
Waiters use a modified form of CLH lock see AbstractQueueSynchronizer
Sequence locks
     * (as used in linux kernels; see Lameter's
     * http://www.lameter.com/gelato2005.pdf
     * and elsewhere; see
     * Boehm's http://www.hpl.hp.com/techreports/2012/HPL-2012-68.html)
     * and Ordered RW locks (see Shirako et al
     * http://dl.acm.org/citation.cfm?id=2312015)

-> each node is tagged as reader / writer
-> sets of reader nodes are grouped/linked -> cowait under a common node so act as single node for most CLH mechanics
-> wegen queue wait-nodes brauchen keine sequenz-nummer, nachfolger ist immer größer als Vorgänger
-> fifo-like scheduling mit Elements of Phase-Fair locks
-> anti barging rule, if a reader arrives while read lock is held but writer is queued, the new reader is queued too
-> complexity in `aquireRead`
-> so that the lock doesn't become unfair
-> aquireWrite + aquireRead -> sehr umfangreiche Methoden, 
-> validation of sequenz-nummern benötigen stärkere ordering-rules than just volatile reads (s. Boehm)
   -> force ordering of reads _before_ validation, in Fällen wo das noch nicht passiert ist, wird Unsafe.loadFence() benutzt
-> memory layout keeps lock state and queue pointers together on the same cache-line
   -> works well for read-mostly loads
-> natural tendency of adaptive-spin CLH locks to reduce memory contention
----

* These rules apply to threads actually queued. All tryLock forms
* opportunistically try to acquire locks regardless of preference
* rules, and so may "barge" their way in.  Randomized spinning is
* used in the acquire methods to reduce (increasingly expensive)
* context switching while also avoiding sustained memory
* thrashing among many threads.  We limit spins to the head of
* queue. A thread spin-waits up to SPINS times (where each
* iteration decreases spin count with 50% probability) before
* blocking. If, upon wakening it fails to obtain lock, and is
* still (or becomes) the first waiting thread (which indicates
* that some other thread barged and obtained lock), it escalates
* spins (up to MAX_HEAD_SPINS) to reduce the likelihood of
* continually losing to barging threads.
*
* Nearly all of these mechanics are carried out in methods
* acquireWrite and acquireRead, that, as typical of such code,
* sprawl out because actions and retries rely on consistent sets
* of locally cached reads.
*
* As noted in Boehm's paper (above), sequence validation (mainly
* method validate()) requires stricter ordering rules than apply
* to normal volatile reads (of "state").  To force orderings of
* reads before a validation and the validation itself in those
* cases where this is not already forced, we use
* Unsafe.loadFence.
*
* The memory layout keeps lock state and queue pointers together
* (normally on the same cache line). This usually works well for
* read-mostly loads. In most other cases, the natural tendency of
* adaptive-spin CLH locks to reduce memory contention lessens
* motivation to further spread out contended locations, but might
* be subject to future improvements.

////

== References

* [KabutzSlides] http://javaspecialists.eu/talks/jfokus13/PhaserAndStampedLock.pdf
* [KabutzNewsletter] http://www.javaspecialists.eu/archive/Issue215.html

* [StampedLock - JavaDoc]https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/locks/StampedLock.html
* [Lock Performance Comparison] http://javaagile.blogspot.co.uk/2014/10/a-lock-for-all-weathers.html 
* [Lock-based vs. Lock-free Algorithms - Thompson]http://mechanical-sympathy.blogspot.com/2013/08/lock-based-vs-lock-free-concurrent.html (code: https://github.com/mjpt777/rw-concurrency)
* [InfoQ - JVM Optimierungen von Locks] http://www.infoq.com/articles/java-threading-optimizations-p1
* [Unsafe xxFence Instruktionen] http://stackoverflow.com/questions/23603304/java-8-unsafe-xxxfence-instructions

////
A capability-based lock with three modes for controlling read/write access. The state of a StampedLock consists of a version and mode. Lock acquisition methods return a stamp that represents and controls access with respect to a lock state; "try" versions of these methods may instead return the special value zero to represent failure to acquire access. Lock release and conversion methods require stamps as arguments, and fail if they do not match the state of the lock. The three modes are:
Writing. Method writeLock() possibly blocks waiting for exclusive access, returning a stamp that can be used in method unlockWrite(long) to release the lock. Untimed and timed versions of tryWriteLock are also provided. When the lock is held in write mode, no read locks may be obtained, and all optimistic read validations will fail.
Reading. Method readLock() possibly blocks waiting for non-exclusive access, returning a stamp that can be used in method unlockRead(long) to release the lock. Untimed and timed versions of tryReadLock are also provided.
Optimistic Reading. Method tryOptimisticRead() returns a non-zero stamp only if the lock is not currently held in write mode. Method validate(long) returns true if the lock has not been acquired in write mode since obtaining a given stamp. This mode can be thought of as an extremely weak version of a read-lock, that can be broken by a writer at any time. The use of optimistic mode for short read-only code segments often reduces contention and improves throughput. However, its use is inherently fragile. Optimistic read sections should only read fields and hold them in local variables for later use after validation. Fields read while in optimistic mode may be wildly inconsistent, so usage applies only when you are familiar enough with data representations to check consistency and/or repeatedly invoke method validate(). For example, such steps are typically required when first reading an object or array reference, and then accessing one of its fields, elements or methods.
This class also supports methods that conditionally provide conversions across the three modes. For example, method tryConvertToWriteLock(long) attempts to "upgrade" a mode, returning a valid write stamp if (1) already in writing mode (2) in reading mode and there are no other readers or (3) in optimistic mode and the lock is available. The forms of these methods are designed to help reduce some of the code bloat that otherwise occurs in retry-based designs.

StampedLocks are designed for use as internal utilities in the development of thread-safe components. Their use relies on knowledge of the internal properties of the data, objects, and methods they are protecting. They are not reentrant, so locked bodies should not call other unknown methods that may try to re-acquire locks (although you may pass a stamp to other methods that can use or convert it). The use of read lock modes relies on the associated code sections being side-effect-free. Unvalidated optimistic read sections cannot call methods that are not known to tolerate potential inconsistencies. Stamps use finite representations, and are not cryptographically secure (i.e., a valid stamp may be guessable). Stamp values may recycle after (no sooner than) one year of continuous operation. A stamp held without use or validation for longer than this period may fail to validate correctly. StampedLocks are serializable, but always deserialize into initial unlocked state, so they are not useful for remote locking.

The scheduling policy of StampedLock does not consistently prefer readers over writers or vice versa. All "try" methods are best-effort and do not necessarily conform to any scheduling or fairness policy. A zero return from any "try" method for acquiring or converting locks does not carry any information about the state of the lock; a subsequent invocation may succeed.

Because it supports coordinated usage across multiple lock modes, this class does not directly implement the Lock or ReadWriteLock interfaces. However, a StampedLock may be viewed asReadLock(), asWriteLock(), or asReadWriteLock() in applications requiring only the associated set of functionality.
////

////
LongAdder, DoubleAdder -> in J8, faster on multithreaded

////

////
== Examples

.example - propagate to heavy read lock
[source,java]
---
StampedLock lock = new StampedLock();
// try the fast (non-blocking) lock first
long stamp = 0L;
try {
  stamp = lock.tryOptimisticRead();
 
  doSomeWork();
 
  if (lock.validate(stamp)) {
   // Great! no contention, the work was successful
  } else {
    // another thread acquired a write lock while we were doing some work, 
    // repeat the operation using the heavy (blocking) lock
    stamp = lock.readLock();
 
    doSomeWork();
  }
} finally {
  // release the lock stamp
  if (stamp != 0L) {
    lock.unlock(stamp);
  }
}
----

.example Point
[source,java]
----
class Point {
  private double x, y;
  private final StampedLock sl = new StampedLock();

  void move(double deltaX, double deltaY) { // an exclusively locked method
    long stamp = sl.writeLock();
    try {
      x += deltaX;
      y += deltaY;
    } finally {
      sl.unlockWrite(stamp);
    }
  }

  double distanceFromOrigin() { // A read-only method
    long stamp = sl.tryOptimisticRead();
    double currentX = x, currentY = y;
    if (!sl.validate(stamp)) {
       stamp = sl.readLock();
       try {
         currentX = x;
         currentY = y;
       } finally {
          sl.unlockRead(stamp);
       }
    }
    return Math.sqrt(currentX * currentX + currentY * currentY);
  }

  void moveIfAtOrigin(double newX, double newY) { // upgrade
    // Could instead start with optimistic, not read mode
    long stamp = sl.readLock();
    try {
      while (x == 0.0 && y == 0.0) {
        long ws = sl.tryConvertToWriteLock(stamp);
        if (ws != 0L) {
          stamp = ws;
          x = newX;
          y = newY;
          break;
        }
        else {
          sl.unlockRead(stamp);
          stamp = sl.writeLock();
        }
      }
    } finally {
      sl.unlock(stamp);
    }
  }
}
----
////