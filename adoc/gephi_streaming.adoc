== Graph-Scripting: Neo4j-Cypher to Gephi-Streaming

=== Replace Yourself with a Shell-Script 

I wanted to connect Gephi's streaming plugin with http://neo4j.org[Neo4j] for a while, but never found the time. 

The idea was to write a server extension that hooks into the http://docs.neo4j.org/chunked/milestone/transactions-events.html[+TransactionEventListener+] and sends updates after the initial state to Gephi which acts as the streaming client.

While re-reading the https://wiki.gephi.org/index.php/Graph_Streaming#Gephi_as_Master[Wiki Page] for the [Streaming Plugin], I realized that there was also a mode where Gephi acts as master and can provide graph data but also receive updates.

Of course that way it's much easier, so we just put on our unix toolbelt and get going.

* +curl+, http://curl.haxx.se/docs/manpage.html[the http power tool]
* Neo4j's docs.neo4j.org/chunked/milestone/rest-api-transactional.html[streaming transactional endpoint] for http://docs.neo4j.org/chunked/milestone/cypher-query-lang.html[Cypher]
* +jq+ which is pure https://github.com/stedolan/jq[json processing awesomeness]
* http://gephi.org[Gephi], the defacto graph visualization toolbench and its
* streaming plugin that talks JSON over http

=== Cypher Streaming Endpoint (Source)

The transactional Cypher endpoint is pretty easy to use but still very powerful. It supports:

* execution of parameterized Cypher queries over the wire
* submitting many statements in the same request
* transaction support (begin, read-write, commit, rollback, timeout) over the wire and across multiple requests
* minimal response format
* streaming queries to and results from the server
* different result formats

The basic request looks like this, sending a list of parameterized _statement_'s to the server:

[source]
----
curl -i -H accept:application/json -H content-type:application/json \
   http://localhost:7474/db/data/transaction \
   -d '{"statements":[
         {"statement":"CREATE (n:Person {name:{nameParam}}) RETURN n", "parameters":{"nameParam":"Mark"}}
         {"statement":"MATCH (n:Person) WHERE name in {names} RETURN n.name as name, head(labels(n)) as label", "parameters":{"names":["Mark","Michael"]}}]}'
----

and receving the results, which look like this:

[source]
----

----

That request open's a transaction whose URL is returned in the location header, and the commit URL provided as part of the response.
The response also contains the column names, result row data, error messages and transaction timeouts.

If you want to continue to read and write to this transaction, just continue to use the transaction URL provided (e.g. /db/data/transaction/42) and when you are finished, either commit via POSTing to the provided commit URL (/db/data/transaction/42/commit) or rollback via a DELETE to your transaction URL.

But we just want to do a simple select that returns us the graph structure, the simplest query for the plain structure would be:

[source,cypher]
----
MATCH (a)-[r]->(b)
RETURN id(a),type(r),id(b)
----

which returns the node-id's of each connection pair in the database as well as the relationship label in between. But we want to have all the data in our graph, so a full query rather looks like this:

[source,cypher]
----
MATCH (a)-[r]->(b) 
RETURN id(a) as a_id, head(labels(a)) as a_label, a, 
       id(b) as b_id, head(labels(b)) as label, b, 
       id(r) as r_id, type(r) as r_type, r
----

This also returns the first label of both nodes, as wells as the property data of the nodes and relationship per row. Of course you're free to limit the query in whatever way you want to only return a certain subgraph.

=== Gephi Streaming Endpoint (Sink)

The Gephi Streaming endpoint is also really easy to set up. You install the *Streaming Plugin* via the "Extras -> Plugins" menu and search for "Graph Streaming" in the "Available Plugins" tab. Install it and restart. Then after you create a new project, you see a "Streaming" tab besides the "Layout" tab in the lower left tool window. In this tab, select "Master", right click "Master Server" and choose "start". The red dot should become green. Now the Gephi streaming service listens on the default port 8080 for your commands. You can quickly try it by issuing the example curl commands from the Gephi Streaming Wiki:

[source,bash]
----
curl "http://localhost:8080/workspace0?operation=updateGraph \
  -d $'{"an":{"0":{"label":"Movie","title":"The Matrix"}}}\r
       {"an":{"1":{"label":"Person","name":"Keanu Reeves"}}}\r
       {"ae":{"0":{"source":"1","target":"0","label":"ACTED_IN","directed":false}}}'
----

You should see two nodes and a relationship pop up in the Gephi rendering window.

[NOTE]
Please note that the expression +$'a\n\r\tb'+ in the shell substitutes the escaped characters with a newline, carriage return and tab ASCII character in the data. This is important as Gephi requires a carriage return as separator between commands. There are two commands +an+ Add Node and +ae+ Add Edge. Both of which take a single or an array of JSON objects +{"_0":{"label":"Movie","title":"The Matrix"}}}+ representing a node or relationship. In these objects we have a unique id as key, which is also used by Gephi to detect if it has to create the element or if it is already there. The entry for that id is another object that then contains the actual properties of the node (and optionally the id and label). For relationships there are two additional fields called +source+, and +target+ containing the id's of the two node elements.

That's all you need to know to remote control Gephi to add Nodes and Relationships. There are other commands, e.g. to delete them again.

=== JSON conversion with JQ, the multifunctional middleman

Cool, now we have our graph structure in JSON. How do we convert this Cypher-JSON-result into the format that the Gephi streaming endpoint expects? Meet +jq+ the JSON power tool. It has a simple language to extract values from JSON either to scalar or list form or even into new JSON documents.

==== Some JQ examples.

|====
|input 
|jq 
|output

|====

In our case we're intrested in the individual +row+ columns of the +result+ +data+, so our jq expression is: +.results[].data[].row+

We now pipe this list of JSON objects into a filter that creates new JSON of the format that the Gephi streaming endpoint expects. Remember, we have to create objects with +an+ and +ae+ entries for the nodes and relationships.
So we reach into the +row+ array by index and pull out id, label, and property data for nodes 1 and 2 and then for the relationship. 

As the property data is alredy a map, we combine it with two new entries for id and label: 
+(.[2] \+ {id:.[0], label:.[1]})+ 

To construct the object with our id as key, we have to convert it into a string, and (as usually entry keys are used literally in jq), we have to enforce evaluation of the expression by putting parentheses around it.
+{((.[0] | tostring)) : ... }+



[source,bash]
----
statement="MATCH (a)-[r]->(b) RETURN id(a) as a_id, head(labels(a)) as a_label, a, id(b) as b_id, head(labels(b)) as label, b, id(r) as r_id, type(r) as r_type, r"

curl -s http://localhost:7474/db/data/transaction/commit -H accept:application/json -H content-type:application/json -d "{\"statements\":[{\"statement\":\"$statement\"}]}" | \
jq -a -c '.results[].data[].row | 
 {an: {((.[0] | tostring)) : (.[2] + {id:.[0], label:.[1]})}},
 {an: {((.[3] | tostring)) : (.[5] + {id:.[3], label:.[4]})}}, 
 {ae: {((.[6] | tostring)) : (.[8] + {source: .[0] | tostring , target: .[3] | tostring, id:.[6], label:.[7]})}}'  | sed -e $'s/}}}/}}}\r/' | \
curl -s -i --data-binary @- -XPOST "http://localhost:8080/workspace0?operation=updateGraph" |\
wc -l
----
